{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cde0886-6c4e-4368-a559-ca3c68cd63fb",
   "metadata": {},
   "source": [
    "# Task 1.6: Building a Network Dataset with NLP\n",
    "\n",
    "### Project: 20th Century Geopolitical Interrelations\n",
    "### Author: Fariya Asghar\n",
    "### Date: 22.07.2025\n",
    "\n",
    "---\n",
    "\n",
    "### Abstract\n",
    "\n",
    "This notebook serves as the core of the Natural Language Processing (NLP) phase for this project. The primary objective is to transform the unstructured text data scraped from the \"Key Events of the 20th Century\" Wikipedia page into a structured dataset suitable for network analysis.\n",
    "\n",
    "The methodology is as follows:\n",
    "1.  **Data Loading:** Ingest the previously scraped list of countries and the full text of 20th-century events.\n",
    "2.  **Text Wrangling:** Standardize the text by replacing common adjectival forms and abbreviations of country names with their official counterparts to improve recognition accuracy.\n",
    "3.  **Named Entity Recognition (NER):** Utilize the `spaCy` library to process the wrangled text, identify all named entities, and segment the document into sentences.\n",
    "4.  **Relationship Extraction:** Filter the sentences to keep only those containing two or more countries. For each of these sentences, create relationship pairs (edges) between the co-occurring countries.\n",
    "5.  **Output:** The final deliverable of this notebook is a structured pandas DataFrame of these relationships. This DataFrame will serve as the direct input for creating, analyzing, and visualizing the geopolitical network in the final task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570e592-0375-47c9-afdb-cc5bf13a8606",
   "metadata": {},
   "source": [
    "### 1. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56759ba-a255-4885-ac4b-f61ff6ee1c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy English language model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Load Data\n",
    "\n",
    "# --- Standard Libraries ---\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools # We will use this for creating relationship pairs\n",
    "\n",
    "# --- NLP and Network Libraries ---\n",
    "import spacy\n",
    "import networkx as nx\n",
    "\n",
    "# --- Load the spaCy English language model ---\n",
    "# Using specific error handling as praised by the mentor.\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy English language model loaded successfully.\")\n",
    "except OSError:\n",
    "    print(\"spaCy 'en_core_web_sm' model not found. Please run 'python -m spacy download en_core_web_sm' in your terminal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ada0863-7504-4dc1-a79f-232c693c953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 209 countries from 'countries_list_20th_century_1.5.csv'.\n",
      "Successfully loaded the raw text from '20th_century_key_events.txt'.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Scraped Data ---\n",
    "# Load the list of countries from the CSV file.\n",
    "try:\n",
    "    countries_df = pd.read_csv('countries_list_20th_century_1.5.csv')\n",
    "    country_list = countries_df['country_name'].tolist()\n",
    "    print(f\"Successfully loaded {len(country_list)} countries from 'countries_list_20th_century_1.5.csv'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'countries_list_20th_century_1.5.csv' not found.\")\n",
    "    country_list = []\n",
    "\n",
    "# Load the raw text from the events page .txt file.\n",
    "try:\n",
    "    with open('20th_century_key_events.txt', 'r', encoding='utf-8') as file:\n",
    "        raw_text = file.read()\n",
    "    print(\"Successfully loaded the raw text from '20th_century_key_events.txt'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: '20th_century_key_events.txt' not found.\")\n",
    "    raw_text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425227b-75b3-4684-93c6-db6aaaea98ed",
   "metadata": {},
   "source": [
    "### 2. EVALUATE AND WRANGLE DATA\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "Before processing the text with the NER model, an evaluation of the raw text and the country list reveals several potential inconsistencies that could reduce accuracy:\n",
    "\n",
    "1.  **Adjectival vs. Noun Forms:** The text frequently uses adjectival forms of country names (e.g., \"German\", \"Soviet\") which may not be correctly identified as the country entity itself (e.g., \"Germany\").\n",
    "2.  **Abbreviations and Acronyms:** Common abbreviations like \"U.S.\" or \"U.K.\" are used instead of their full names.\n",
    "3.  **Historical Names:** The term \"Soviet Union\" is prevalent and, for the scope of this analysis, should be mapped to \"Russia\" to maintain a consistent entity.\n",
    "\n",
    "**Plan:**\n",
    "\n",
    "To address these issues, I will perform a series of text replacements on the raw text. This wrangling process will standardize common abbreviations and adjectival forms to their corresponding official country names. This will create a cleaner, more consistent text, significantly improving the performance of the `spaCy` NER model in identifying the geopolitical entities of interest. The final, wrangled text will be saved to a new `.txt` file for traceability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b35bf-8e47-4411-9dbe-b4b56ee8bed4",
   "metadata": {},
   "source": [
    "#### - Automated Text Wrangling with pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8316c79-78cd-4e3d-92c6-fa00db31ab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automated text wrangling using pycountry...\n",
      "Searching for adjectival forms for all countries in the list...\n",
      "Built a replacement dictionary with 3 rules.\n",
      "Applying replacements to the text...\n",
      "Automated text wrangling complete.\n",
      "Wrangled text saved to '20th_century_wrangled_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "\n",
    "print(\"Starting automated text wrangling using pycountry...\")\n",
    "wrangled_text = raw_text\n",
    "\n",
    "# --- Part 1: Automatically build a comprehensive replacement dictionary ---\n",
    "replacement_dict = {\n",
    "    # Add a few common, non-standard cases manually that pycountry might miss\n",
    "    \"U.S.\": \"United States\",\n",
    "    \"U.K.\": \"United Kingdom\",\n",
    "    \"Soviet Union\": \"Russia\"\n",
    "}\n",
    "\n",
    "# Loop through our country list to find adjectival forms\n",
    "print(\"Searching for adjectival forms for all countries in the list...\")\n",
    "for country_name in country_list:\n",
    "    try:\n",
    "        # Search for the country in the pycountry database\n",
    "        country_data = pycountry.countries.get(name=country_name)\n",
    "        \n",
    "        # Check if the country has an 'adjective' attribute\n",
    "        if country_data and hasattr(country_data, 'adjective'):\n",
    "            adjective = country_data.adjective\n",
    "            \n",
    "            # Add a rule to replace the adjective with the proper country name\n",
    "            # e.g., \"German\" -> \"Germany\"\n",
    "            # We only add it if it's not already in our manual list\n",
    "            if adjective not in replacement_dict:\n",
    "                 replacement_dict[adjective] = country_name\n",
    "                 \n",
    "    except LookupError:\n",
    "        # This country isn't in the pycountry database, which is fine. We just skip it.\n",
    "        continue\n",
    "\n",
    "print(f\"Built a replacement dictionary with {len(replacement_dict)} rules.\")\n",
    "\n",
    "\n",
    "# --- Part 2: Apply all replacements to the text ---\n",
    "print(\"Applying replacements to the text...\")\n",
    "# Loop through the dictionary and apply each replacement\n",
    "for old_word, new_word in replacement_dict.items():\n",
    "    # Use re.sub with word boundaries (\\b) for case-insensitive replacement to avoid\n",
    "    # replacing parts of words (e.g., 'us' in 'unanimous').\n",
    "    wrangled_text = re.sub(f'\\\\b{re.escape(old_word)}\\\\b', new_word, wrangled_text, flags=re.IGNORECASE)\n",
    "\n",
    "print(\"Automated text wrangling complete.\")\n",
    "\n",
    "\n",
    "# --- Part 3: Save the wrangled text as required ---\n",
    "wrangled_filename = \"20th_century_wrangled_text.txt\"\n",
    "with open(wrangled_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(wrangled_text)\n",
    "print(f\"Wrangled text saved to '{wrangled_filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ce956-2550-4539-9179-02ec6715ed31",
   "metadata": {},
   "source": [
    "### 3. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00502364-41de-49fc-89d1-ec05f22d6859",
   "metadata": {},
   "source": [
    "#### - Create the NER Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45fee1e-3f96-48d2-8683-d2e160d28143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the wrangled text with spaCy to create the NER object...\n",
      "NER processing complete.\n",
      "\n",
      "--- Sample of the first 15 Entities Found by spaCy ---\n",
      "Entity: 'The 20th century', Label: 'DATE'\n",
      "Entity: 'The World Wars', Label: 'ORG'\n",
      "Entity: 'the Cold War', Label: 'EVENT'\n",
      "Entity: 'the Space Race', Label: 'ORG'\n",
      "Entity: 'the World Wide Web', Label: 'EVENT'\n",
      "Entity: 'the 21st century', Label: 'DATE'\n",
      "Entity: 'today', Label: 'DATE'\n",
      "Entity: 'Historic', Label: 'PERSON'\n",
      "Entity: '20th', Label: 'ORDINAL'\n",
      "Entity: 'the 20th century', Label: 'DATE'\n",
      "Entity: 'The 1900s', Label: 'DATE'\n",
      "Entity: 'the decade', Label: 'DATE'\n",
      "Entity: '1914', Label: 'CARDINAL'\n",
      "Entity: 'the Panama Canal', Label: 'FAC'\n",
      "Entity: 'Scramble', Label: 'PERSON'\n"
     ]
    }
   ],
   "source": [
    "# The nlp() function processes the text and performs the NER analysis.\n",
    "print(\"Processing the wrangled text with spaCy to create the NER object...\")\n",
    "ner_object = nlp(wrangled_text)\n",
    "print(\"NER processing complete.\")\n",
    "\n",
    "# Let's inspect a sample of the entities spaCy found to verify its work.\n",
    "print(\"\\n--- Sample of the first 15 Entities Found by spaCy ---\")\n",
    "for entity in list(ner_object.ents)[:15]:\n",
    "    print(f\"Entity: '{entity.text}', Label: '{entity.label_}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73e096-fcd8-4bca-a119-90c238919f88",
   "metadata": {},
   "source": [
    "#### - Split the NER Object into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb82591-355c-4b51-adfb-877656672adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting entities from each sentence...\n",
      "DataFrame of sentences and their entities created successfully.\n",
      "\n",
      "--- First 10 Sentences and Their Entities ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The 20th century changed the world in unpreced...</td>\n",
       "      <td>[The 20th century]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The World Wars sparked tension between countri...</td>\n",
       "      <td>[The World Wars, the Cold War, the Space Race,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These advancements have played a significant r...</td>\n",
       "      <td>[the 21st century, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Historic events in the 20th century[edit]\\nWor...</td>\n",
       "      <td>[Historic, 20th, the 20th century]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 1900s saw the decade herald a series of in...</td>\n",
       "      <td>[The 1900s, the decade]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1914 saw the completion of the Panama Canal.\\n</td>\n",
       "      <td>[1914, the Panama Canal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Scramble for Africa continued in the 1900s...</td>\n",
       "      <td>[Scramble, Africa, the 1900s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The atrocities in the Congo Free State shocked...</td>\n",
       "      <td>[the Congo Free State]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From 1914 to 1918, the First World War, and it...</td>\n",
       "      <td>[1914 to 1918, the First World War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"The war to end all wars\": World War I (1914–1...</td>\n",
       "      <td>[World War I, World War I\\nArrest, Sarajevo, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The 20th century changed the world in unpreced...   \n",
       "1  The World Wars sparked tension between countri...   \n",
       "2  These advancements have played a significant r...   \n",
       "3  Historic events in the 20th century[edit]\\nWor...   \n",
       "4  The 1900s saw the decade herald a series of in...   \n",
       "5     1914 saw the completion of the Panama Canal.\\n   \n",
       "6  The Scramble for Africa continued in the 1900s...   \n",
       "7  The atrocities in the Congo Free State shocked...   \n",
       "8  From 1914 to 1918, the First World War, and it...   \n",
       "9  \"The war to end all wars\": World War I (1914–1...   \n",
       "\n",
       "                                            entities  \n",
       "0                                 [The 20th century]  \n",
       "1  [The World Wars, the Cold War, the Space Race,...  \n",
       "2                          [the 21st century, today]  \n",
       "3                 [Historic, 20th, the 20th century]  \n",
       "4                            [The 1900s, the decade]  \n",
       "5                           [1914, the Panama Canal]  \n",
       "6                      [Scramble, Africa, the 1900s]  \n",
       "7                             [the Congo Free State]  \n",
       "8                [1914 to 1918, the First World War]  \n",
       "9  [World War I, World War I\\nArrest, Sarajevo, A...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty list to store our sentence-level data.\n",
    "sentence_data = []\n",
    "\n",
    "# The .sents attribute of the spaCy Doc object allows us to loop through each identified sentence.\n",
    "print(\"Extracting entities from each sentence...\")\n",
    "for sentence in ner_object.sents:\n",
    "    # For each sentence, we create a list of the text of every entity found within it.\n",
    "    entity_list = [ent.text for ent in sentence.ents]\n",
    "    \n",
    "    # We append a dictionary containing the sentence and its entities to our main list.\n",
    "    sentence_data.append({\"sentence\": sentence.text, \"entities\": entity_list})\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame for easier handling.\n",
    "sentences_df = pd.DataFrame(sentence_data)\n",
    "\n",
    "print(\"DataFrame of sentences and their entities created successfully.\")\n",
    "\n",
    "# Display the head of the new DataFrame to verify the result.\n",
    "print(\"\\n--- First 10 Sentences and Their Entities ---\")\n",
    "display(sentences_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3951eb-c61a-48fb-8838-2c9a954d8fb4",
   "metadata": {},
   "source": [
    "### 4. Relationship Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcfb8fd-4d81-4c32-a424-b1966c0016ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20th century changed the world in unprecedented ways. The World Wars sparked tension between countries and led to the creation of atomic bombs, the Cold War led to the Space Race and the creation of space-based rockets, and the World Wide Web was created. These advancements have played a significant role in citizens' lives and shaped the 21st century into what it is today.\n",
      "Historic events in the 20th century[edit]\n",
      "World at the beginning of the century[edit]\n",
      "Main article: Edwardian era\n",
      "The new beginning of the 20th century marked significant changes. The 1900s saw the decade herald a series of inventions, including the automobile, airplane and radio broadcasting. 1914 saw the completion of the Panama Canal.\n",
      "The Scramble for Africa continued in the 1900s and resulted in wars and genocide across the continent. The atrocities in the Congo Free State shocked the civilized world.\n",
      "From 1914 to 1918, the First World War, and its aftermath, caused major changes in the power balance of the world, destroying or transforming some of the most powerful empires.\n",
      "\"The war to end all wars\": World War I (1914–1918)[edit]\n",
      "Main article: World War I\n",
      "Arrest of a suspect in Sarajevo following the Assassination of Archduke Franz Ferdinand\n",
      "The First World War (or simply WWI), termed \"The Great War\" by contemporaries, started in July 1914 and ended in November 1918. The war was precipitated by the Assassination in Sarajevo of the Austro-Hungarian Empire's heir to the throne, Erzherzog Franz Ferdinand, by Gavrilo Princip, a member of the Young Bosnia liberation movement. After a period of diplomatic and military escalation known as the July Crisis, by the end of July 1914 two coalitions were at war: the Allies, comprised initially of the British Empire, France, and the Russian Empire; and the Central Powers, comprised initially of the German Empire and Austria-Hungary.[1][2]\n",
      "In 1917, Russia ended hostile actions against the Central Powers after the fall of the Tsar. The Bolsheviks negotia\n"
     ]
    }
   ],
   "source": [
    "print(wrangled_text[:2000]) # Print the first 2000 characters of the wrangled text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072190e-6324-422b-a52b-fc66a810dd08",
   "metadata": {},
   "source": [
    "#### - Filter the Entities for Countries Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cea8b3b-ceaa-4c1f-b0bf-09c4a4aa2ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a robust search map from the country list...\n",
      "Search map built successfully.\n",
      "Filtering sentences using the new search map...\n",
      "\n",
      "Filtering complete. Found 632 sentences that mention at least one country.\n",
      "\n",
      "--- First 10 Sentences Containing Country Entities ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>country_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The 20th century changed the world in unpreced...</td>\n",
       "      <td>[   Saint Vincent and the Grenadines ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The World Wars sparked tension between countri...</td>\n",
       "      <td>[   Trinidad and Tobago ,    Saint Vincent and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These advancements have played a significant r...</td>\n",
       "      <td>[   Trinidad and Tobago ,    Saint Vincent and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Historic events in the 20th century[edit]\\nWor...</td>\n",
       "      <td>[   Papua New Guinea ,    Saint Vincent and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 1900s saw the decade herald a series of in...</td>\n",
       "      <td>[   Trinidad and Tobago ,    Saint Vincent and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1914 saw the completion of the Panama Canal.</td>\n",
       "      <td>[   Panama ,    Saint Vincent and the Grenadin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Scramble for Africa continued in the 1900s...</td>\n",
       "      <td>[   South Africa ,    Trinidad and Tobago ,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The atrocities in the Congo Free State shocked...</td>\n",
       "      <td>[   Saint Vincent and the Grenadines ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From 1914 to 1918, the First World War, and it...</td>\n",
       "      <td>[   Trinidad and Tobago ,    Saint Vincent and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"The war to end all wars\": World War I (1914–1...</td>\n",
       "      <td>[   Trinidad and Tobago ,    Saint Vincent and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  The 20th century changed the world in unpreced...   \n",
       "1  The World Wars sparked tension between countri...   \n",
       "2  These advancements have played a significant r...   \n",
       "3  Historic events in the 20th century[edit]\\nWor...   \n",
       "4  The 1900s saw the decade herald a series of in...   \n",
       "5       1914 saw the completion of the Panama Canal.   \n",
       "6  The Scramble for Africa continued in the 1900s...   \n",
       "7  The atrocities in the Congo Free State shocked...   \n",
       "8  From 1914 to 1918, the First World War, and it...   \n",
       "9  \"The war to end all wars\": World War I (1914–1...   \n",
       "\n",
       "                                    country_entities  \n",
       "0             [   Saint Vincent and the Grenadines ]  \n",
       "1  [   Trinidad and Tobago ,    Saint Vincent and...  \n",
       "2  [   Trinidad and Tobago ,    Saint Vincent and...  \n",
       "3  [   Papua New Guinea ,    Saint Vincent and th...  \n",
       "4  [   Trinidad and Tobago ,    Saint Vincent and...  \n",
       "5  [   Panama ,    Saint Vincent and the Grenadin...  \n",
       "6  [   South Africa ,    Trinidad and Tobago ,   ...  \n",
       "7             [   Saint Vincent and the Grenadines ]  \n",
       "8  [   Trinidad and Tobago ,    Saint Vincent and...  \n",
       "9  [   Trinidad and Tobago ,    Saint Vincent and...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1. BUILD A ROBUST SEARCH MAP ===\n",
    "# We create a dictionary that maps a single keyword (e.g., \"states\") back to its full, official country name.\n",
    "print(\"Building a robust search map from the country list...\")\n",
    "country_search_map = {}\n",
    "for country in country_list:\n",
    "    # Get the individual words from the country name\n",
    "    words = country.lower().split()\n",
    "    for word in words:\n",
    "        # We only want meaningful words, not short ones like 'of' or 'the'\n",
    "        if len(word) > 2:\n",
    "            country_search_map[word] = country\n",
    "print(\"Search map built successfully.\")\n",
    "\n",
    "\n",
    "# === 2. THE SIMPLE AND DIRECT FILTERING LOGIC ===\n",
    "filtered_data = []\n",
    "print(\"Filtering sentences using the new search map...\")\n",
    "\n",
    "# Use spaCy's reliable sentence splitter from the ner_object.\n",
    "for sentence in ner_object.sents:\n",
    "    # This set will store the unique OFFICIAL country names found in this sentence.\n",
    "    countries_found_in_sentence = set()\n",
    "    \n",
    "    # Tokenize the sentence into a clean list of lowercase words.\n",
    "    sentence_words = re.findall(r'\\b\\w+\\b', sentence.text.lower())\n",
    "    \n",
    "    # For each word in the sentence, check if it's a country keyword.\n",
    "    for word in sentence_words:\n",
    "        if word in country_search_map:\n",
    "            # If it is, add the corresponding OFFICIAL country name to our set.\n",
    "            official_name = country_search_map[word]\n",
    "            countries_found_in_sentence.add(official_name)\n",
    "            \n",
    "    # If we found at least one country in this sentence...\n",
    "    if countries_found_in_sentence:\n",
    "        filtered_data.append({\n",
    "            \"sentence\": sentence.text.strip(),\n",
    "            \"country_entities\": list(countries_found_in_sentence)\n",
    "        })\n",
    "\n",
    "# === 3. CREATE THE FINAL DATAFRAME ===\n",
    "filtered_sentences_df = pd.DataFrame(filtered_data)\n",
    "\n",
    "print(f\"\\nFiltering complete. Found {len(filtered_sentences_df)} sentences that mention at least one country.\")\n",
    "\n",
    "# Display the head of the filtered DataFrame to confirm it is populated.\n",
    "print(\"\\n--- First 10 Sentences Containing Country Entities ---\")\n",
    "display(filtered_sentences_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6dd47-03b1-428f-89a2-ccccfb7dda92",
   "metadata": {},
   "source": [
    "#### - Create the Relationships DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee83b92-bad3-4bff-a5b6-6028bbcd7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a DataFrame with 1413 relationship pairs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Panama</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 source                                target\n",
       "0     Saint Vincent and the Grenadines                   Trinidad and Tobago \n",
       "1     Saint Vincent and the Grenadines                   Trinidad and Tobago \n",
       "2                     Papua New Guinea      Saint Vincent and the Grenadines \n",
       "3     Saint Vincent and the Grenadines                   Trinidad and Tobago \n",
       "4                               Panama      Saint Vincent and the Grenadines \n",
       "5     Saint Vincent and the Grenadines                          South Africa \n",
       "6     Saint Vincent and the Grenadines                   Trinidad and Tobago \n",
       "7                         South Africa                   Trinidad and Tobago \n",
       "8     Saint Vincent and the Grenadines                   Trinidad and Tobago \n",
       "9     Saint Vincent and the Grenadines                   Trinidad and Tobago "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This list will store all the relationship pairs we find.\n",
    "relationships = []\n",
    "\n",
    "# Loop through each row of our correctly filtered DataFrame.\n",
    "for index, row in filtered_sentences_df.iterrows():\n",
    "    countries = row['country_entities']\n",
    "    \n",
    "    # We only care about sentences that mention at least TWO countries.\n",
    "    if len(countries) > 1:\n",
    "        # The itertools.combinations function is perfect for this.\n",
    "        # It creates all unique pairs from a list.\n",
    "        # e.g., for ['A', 'B', 'C'], it will generate ('A', 'B'), ('A', 'C'), ('B', 'C')\n",
    "        for pair in itertools.combinations(sorted(countries), 2):\n",
    "            relationships.append(pair)\n",
    "\n",
    "# Convert the list of pairs into a DataFrame.\n",
    "relationships_df = pd.DataFrame(relationships, columns=['source', 'target'])\n",
    "\n",
    "print(f\"Created a DataFrame with {len(relationships_df)} relationship pairs.\")\n",
    "\n",
    "# Display the first 10 relationships found.\n",
    "display(relationships_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fdd06-657d-4f4f-8ccb-bf092d28b826",
   "metadata": {},
   "source": [
    "### 5. OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bbdabcd-9d0f-4cf7-86ea-42c046a2edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 15 Country Relationships by Frequency ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>United States</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>United States</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>East Timor</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>South Ossetia</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source  \\\n",
       "0      Saint Vincent and the Grenadines    \n",
       "1                      Papua New Guinea    \n",
       "2                                Russia    \n",
       "3      Saint Vincent and the Grenadines    \n",
       "4                               Germany    \n",
       "5                      Papua New Guinea    \n",
       "6                                Russia    \n",
       "7                                 Japan    \n",
       "8                   Trinidad and Tobago    \n",
       "9                               Germany    \n",
       "10                                Japan    \n",
       "11     Saint Vincent and the Grenadines    \n",
       "12     Saint Vincent and the Grenadines    \n",
       "13                      North Macedonia    \n",
       "14                        South Ossetia    \n",
       "\n",
       "                                  target  value  \n",
       "0                   Trinidad and Tobago     228  \n",
       "1      Saint Vincent and the Grenadines      39  \n",
       "2      Saint Vincent and the Grenadines      38  \n",
       "3                         United States      37  \n",
       "4      Saint Vincent and the Grenadines      34  \n",
       "5                   Trinidad and Tobago      28  \n",
       "6                   Trinidad and Tobago      28  \n",
       "7      Saint Vincent and the Grenadines      26  \n",
       "8                         United States      25  \n",
       "9                   Trinidad and Tobago      21  \n",
       "10                  Trinidad and Tobago      18  \n",
       "11                           East Timor      17  \n",
       "12                         South Africa      16  \n",
       "13     Saint Vincent and the Grenadines      14  \n",
       "14                  Trinidad and Tobago      12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Finalize and Count Relationships ---\n",
    "\n",
    "# To treat (A, B) and (B, A) as the same relationship, we will sort each pair alphabetically.\n",
    "# This ensures that 'Germany' and 'Japan' always becomes ('Germany', 'Japan'), never ('Japan', 'Germany').\n",
    "sorted_relationships = [tuple(sorted(pair)) for pair in relationships]\n",
    "\n",
    "# Create a new DataFrame from the sorted pairs.\n",
    "sorted_df = pd.DataFrame(sorted_relationships, columns=['source', 'target'])\n",
    "\n",
    "# Now, we count the occurrences of each unique, sorted pair.\n",
    "final_relationships_df = sorted_df.value_counts().reset_index()\n",
    "final_relationships_df.columns = ['source', 'target', 'value']\n",
    "\n",
    "# Display the top 15 most frequent relationships.\n",
    "print(\"--- Top 15 Country Relationships by Frequency ---\")\n",
    "display(final_relationships_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c687ea-233a-4652-b268-c27feb534500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved the final relationships data to 'country_relationships.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --- Save and Export Your DataFrame ---\n",
    "output_filename = \"country_relationships.csv\"\n",
    "final_relationships_df.to_csv(output_filename, index=False)\n",
    "print(f\"\\nSuccessfully saved the final relationships data to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f348bd-dbad-43c9-8fc1-73ec2897138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:20th_century] *",
   "language": "python",
   "name": "conda-env-20th_century-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
